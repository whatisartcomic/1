<!DOCTYPE html>
<html lang="en">
<head>
  <script> document.documentElement.classList.add('ready');</script>
  <style>    html { visibility: hidden; }
    html.ready { visibility: visible; }</style>
  <meta charset="UTF-8">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Borel&display=swap" rel="stylesheet">
  <title>WHAT IS ART?</title> 
  <link rel="stylesheet" href="style.css">


<!-- Apple touch icon (for iOS home‐screen bookmarks) -->
<link rel="apple-touch-icon" sizes="180x180" href="/1/apple-touch-icon.png">

<!-- Standard favicons -->
<link rel="icon" type="image/png" sizes="32x32" href="/1/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/1/favicon-16x16.png">

<!-- Android Chrome icons (used by some Android browsers and PWA installers) -->
<link rel="icon" type="image/png" sizes="192x192" href="/1/android-chrome-192x192.png">
<link rel="icon" type="image/png" sizes="512x512" href="/1/android-chrome-512x512.png">

<!-- Web app manifest (for PWA metadata) -->
<link rel="manifest" href="/1/site.webmanifest">

<!-- Fallback for older browsers -->
<link rel="shortcut icon" href="/favicon.ico">

<!-- Theme color for mobile address‐bar -->
<meta name="theme-color" content="#ffffff">

  
</head>
<body>
  <div id="gallery">
    
    <div id="flipbook" style="visibility: hidden;"></div>
    <div class="haiku">
      <p id="haikuDisplay"></p>
    </div>
    <button id="nextBtn">?</button>
  </div>

<script
  src="https://code.jquery.com/jquery-3.7.1.min.js"
  integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo="
  crossorigin="anonymous"></script>
  <!-- 2. Turn.js -->
  <script src="turn.js"></script>
  <!-- 3. Logic -->
  <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11"></script>
  <script src="script.js"></script>
<script>
  // ─── 1) Pick a “soft” English voice if possible ─────────────────────────❍
  function getSoftEnglishVoice(voices) {
    // Prefer female‐leaning names that tend to sound gentle/soft:
    // “Samantha”, “Zira”, “Linda”, “Amy” (common on macOS/Windows/Chrome).
    const soft = voices
      .filter(v => v.lang.startsWith('en') && /(Samantha|Zira|Linda|Amy)/i.test(v.name))
      .sort((a, b) => a.name.localeCompare(b.name));
    if (soft.length) return soft[0];

    // Otherwise, fallback to the first English‐language voice found
    const fallback = voices.filter(v => v.lang.startsWith('en'));
    return fallback.length ? fallback[0] : null;
  }

  // ─── 2) Return a Promise that resolves once speechSynthesis.getVoices() is non‐empty ──❍
  function waitForVoices() {
    return new Promise(resolve => {
      const loaded = window.speechSynthesis.getVoices();
      if (loaded.length) {
        resolve(loaded);
      } else {
        // onvoiceschanged fires when the browser has populated its voice list
        window.speechSynthesis.onvoiceschanged = () => {
          const now = window.speechSynthesis.getVoices();
          if (now.length) {
            resolve(now);
          }
        };
      }
    });
  }

  // ─── 3) Return a Promise that resolves once #haikuDisplay.innerText is non‐empty ─ ❍
  function waitForInitialContent() {
    return new Promise(resolve => {
      const container = document.getElementById('haikuDisplay');
      if (!container) {
        // If element doesn’t exist, resolve immediately (avoids hanging)
        resolve();
        return;
      }
      // If it already has text, resolve right away
      if (container.innerText.trim()) {
        resolve();
        return;
      }
      // Otherwise, observe until text appears
      const observer = new MutationObserver(() => {
        if (container.innerText.trim()) {
          observer.disconnect();
          resolve();
        }
      });
      observer.observe(container, {
        childList: true,
        subtree: true,
        characterData: true
      });
    });
  }

  // ─── 4) Warm‐up function: issue a zero‐volume utterance so the engine is fully initialized ─❍
  function warmUpTtsEngine(chosenVoice) {
    return new Promise(resolve => {
      const warmup = new SpeechSynthesisUtterance(' '); // single space
      warmup.voice = chosenVoice;
      warmup.volume = 0;     // silent
      warmup.rate   = 1;     // normal rate
      warmup.pitch  = 1;     // normal pitch

      // Once the silent utterance ends, we know the engine is “ready”
      warmup.onend = () => resolve();

      // Fire it off immediately. It won’t be heard, but forces the TTS engine to load.
      window.speechSynthesis.speak(warmup);
    });
  }

  // ─── 5) Global variable to hold our locked‐in voice ─────────────────────────❍
  let chosenVoice = null;

  // ─── 6) Chain together:
  //      (a) wait for voices → (b) pick voice → (c) warm up engine →
  //      (d) wait for initial content → (e) speak with a slight delay ────❍
  const voicePromise   = waitForVoices();
  const contentPromise = waitForInitialContent();

  voicePromise
    .then(voices => {
      chosenVoice = getSoftEnglishVoice(voices);
      if (!chosenVoice) {
        console.warn('No suitable English voice found.');
        throw new Error('No voice');
      }
      return warmUpTtsEngine(chosenVoice);
    })
    .then(() => {
      // Now that the engine is warmed up, wait for first haiku text:
      return contentPromise;
    })
    .then(() => {
      // Add a short pause to let the browser finish rendering the text
      setTimeout(() => {
        speakHaikuText();
      }, 75); // 75 ms “render buffer”
    })
    .catch(err => {
      // If something failed (no voices, etc.), we just don’t speak on page load
      console.error('TTS setup error:', err);
    });

  // ─── 7) Synchronous function to speak whatever is in #haikuDisplay ───────❍
  function speakHaikuText() {
    if (!chosenVoice) return; // bail if voice isn’t ready
    const container = document.getElementById('haikuDisplay');
    if (!container) return;

    const textToSpeak = container.innerText.trim();
    if (!textToSpeak) return;

    const utter = new SpeechSynthesisUtterance(textToSpeak);
    utter.voice = chosenVoice;

    // ───── Softening parameters ──────────────────────────────────────────❍
    utter.rate   = 0.85; // 15% slower
    utter.pitch  = 0.9;  // slightly lower
    utter.volume = 0.8;  // 80% volume

    // Cancel any in‐progress speech, then speak
    window.speechSynthesis.cancel();
    window.speechSynthesis.speak(utter);
  }

  // ─── 8) Observe #haikuDisplay so that on any AJAX/text change we re‐speak ───❍
  (function observeHaikuChanges() {
    const targetNode = document.getElementById('haikuDisplay');
    if (!targetNode) return;

    let throttleTimeout = null;
    const throttledSpeak = () => {
      if (throttleTimeout) clearTimeout(throttleTimeout);
      throttleTimeout = setTimeout(() => {
        // Before speaking, give an extra 2500 ms for DOM updates to finish
        setTimeout(speakHaikuText, 2500);
        throttleTimeout = null;
      }, 250);
    };

    const observerConfig = {
      childList: true,      // new/removed child nodes
      subtree: true,        // any descendant changes
      characterData: true   // text node updates
    };

    const observer = new MutationObserver(throttledSpeak);
    observer.observe(targetNode, observerConfig);
  })();
</script>



</body>
</html>
